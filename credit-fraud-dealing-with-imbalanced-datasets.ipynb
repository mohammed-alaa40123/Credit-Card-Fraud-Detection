{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 align=\"center\"> Credit Fraud Detector </h1>","metadata":{"_cell_guid":"3689760c-41f8-4a33-9c96-3fd17803950e","_uuid":"3e0ad409d438c7c68ea6a76700a1e964a357453f"}},{"cell_type":"code","source":"# Imported Libraries\n\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Classifier Libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n\n# Other Libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_predictfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import roc_auc_score, classification_report\n\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-05-14T08:35:16.959764Z","iopub.execute_input":"2023-05-14T08:35:16.960349Z","iopub.status.idle":"2023-05-14T08:35:16.971834Z","shell.execute_reply.started":"2023-05-14T08:35:16.960065Z","shell.execute_reply":"2023-05-14T08:35:16.970915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf = pd.read_csv('../input/creditcard.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T08:02:56.510146Z","iopub.execute_input":"2023-05-14T08:02:56.510904Z","iopub.status.idle":"2023-05-14T08:02:59.799794Z","shell.execute_reply.started":"2023-05-14T08:02:56.510828Z","shell.execute_reply":"2023-05-14T08:02:59.798993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T08:02:59.801469Z","iopub.execute_input":"2023-05-14T08:02:59.801945Z","iopub.status.idle":"2023-05-14T08:02:59.944207Z","shell.execute_reply.started":"2023-05-14T08:02:59.801879Z","shell.execute_reply":"2023-05-14T08:02:59.943296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"_kg_hide-input":true,"_cell_guid":"376ce881-463a-4a09-9ac0-c63f85577eec","_uuid":"93031e732e5aca3a2b4984799d6bf58d76e4b52d","execution":{"iopub.status.busy":"2023-05-14T08:02:59.945997Z","iopub.execute_input":"2023-05-14T08:02:59.946329Z","iopub.status.idle":"2023-05-14T08:03:00.692600Z","shell.execute_reply.started":"2023-05-14T08:02:59.946270Z","shell.execute_reply":"2023-05-14T08:03:00.691582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Except for the transaction and amount we dont know what the other columns are (**due to privacy reasons**). The only thing we know, is that those columns that are unknown have been scaled already.","metadata":{}},{"cell_type":"code","source":"# No Null Values!\ndf.isnull().sum().max()","metadata":{"_kg_hide-input":true,"_cell_guid":"03ddb929-5bc8-4af4-90cd-21dcbb57560d","_uuid":"38bec67888aa534e9739e95ef9fac62d27a87021","execution":{"iopub.status.busy":"2023-05-14T08:03:00.694245Z","iopub.execute_input":"2023-05-14T08:03:00.694678Z","iopub.status.idle":"2023-05-14T08:03:00.831129Z","shell.execute_reply.started":"2023-05-14T08:03:00.694605Z","shell.execute_reply":"2023-05-14T08:03:00.830237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"_kg_hide-input":true,"_cell_guid":"6a526b6c-8463-4f6f-92b0-e8a3a21cbb2e","_uuid":"479a5f12d3dd68262316a17b4b7b3499e0a2cbe0","execution":{"iopub.status.busy":"2023-05-14T08:03:00.834115Z","iopub.execute_input":"2023-05-14T08:03:00.834394Z","iopub.status.idle":"2023-05-14T08:03:00.841238Z","shell.execute_reply.started":"2023-05-14T08:03:00.834349Z","shell.execute_reply":"2023-05-14T08:03:00.840267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The classes are heavily skewed(imbalanced).\nprint('No Frauds', round(df['Class'].value_counts()[0]/len(df) * 100,2), '% of the dataset')\nprint('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset')","metadata":{"_kg_hide-input":true,"_cell_guid":"01c007fa-0fcc-4eea-84ff-0861a2f8c533","_uuid":"f6b96ff34855e3bf7af1f6979342b01c473e4e07","execution":{"iopub.status.busy":"2023-05-14T08:03:00.842812Z","iopub.execute_input":"2023-05-14T08:03:00.843084Z","iopub.status.idle":"2023-05-14T08:03:00.865591Z","shell.execute_reply.started":"2023-05-14T08:03:00.843038Z","shell.execute_reply":"2023-05-14T08:03:00.864741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Class.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T08:03:00.867221Z","iopub.execute_input":"2023-05-14T08:03:00.867572Z","iopub.status.idle":"2023-05-14T08:03:00.880076Z","shell.execute_reply.started":"2023-05-14T08:03:00.867511Z","shell.execute_reply":"2023-05-14T08:03:00.879055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of the transactions are non-fraud. Our original datasetis **imbalanced**!  If we use this dataframe as the base for our predictive models our algorithms will probably overfit since it will \"assume\" that most transactions are not fraud.","metadata":{"_cell_guid":"558c9b60-3f52-4da5-92fa-9fc4acbdbb3a","_uuid":"c2bb0945a312508e908386fc87adc227f0afe0e0"}},{"cell_type":"code","source":"colors = [\"#FFA500\", \"#00FF00\"]\n\nsns.countplot('Class', data=df, palette=colors)\nplt.title('Fraud distribution', fontsize=14)","metadata":{"_kg_hide-input":true,"_cell_guid":"657bc987-4b15-4cfa-b290-c39a2632e2ac","_uuid":"337caaf6ed3f65beedb24a74eebb22d97ff52ba4","execution":{"iopub.status.busy":"2023-05-14T08:03:00.881369Z","iopub.execute_input":"2023-05-14T08:03:00.881657Z","iopub.status.idle":"2023-05-14T08:03:01.063652Z","shell.execute_reply.started":"2023-05-14T08:03:00.881617Z","shell.execute_reply":"2023-05-14T08:03:01.062743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(18,4))\n\namount_val = df['Amount'].values\ntime_val = df['Time'].values\n\nsns.distplot(amount_val, ax=ax[0], color='r')\nax[0].set_title('Distribution of Transaction Amount', fontsize=14)\n\nsns.distplot(time_val, ax=ax[1], color='b')\nax[1].set_title('Distribution of Transaction Time', fontsize=14)\n\n\n\nplt.show()","metadata":{"_kg_hide-input":true,"_cell_guid":"cee315f2-325f-42b6-a640-736f10c272cc","_uuid":"cfa51792bf6f8a6b318ae1bffcff4e922b1d1917","execution":{"iopub.status.busy":"2023-05-14T08:03:01.066992Z","iopub.execute_input":"2023-05-14T08:03:01.067377Z","iopub.status.idle":"2023-05-14T08:03:03.543219Z","shell.execute_reply.started":"2023-05-14T08:03:01.067321Z","shell.execute_reply":"2023-05-14T08:03:03.541802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scaling Time and amount ","metadata":{}},{"cell_type":"code","source":"# Since most of our data has already been scaled we should scale the columns that are left to scale (Amount and Time)\nfrom sklearn.preprocessing import RobustScaler\n\n# RobustScaler is less prone to outliers.\n\nrob_scaler = RobustScaler()\n\ndf['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\ndf['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n\ndf.drop(['Time','Amount'], axis=1, inplace=True)","metadata":{"_kg_hide-input":true,"_cell_guid":"d5d64bf0-2fbb-4096-a265-f68887bf2fde","_uuid":"1501ec379c9b5c39c3857ba0febd0aedee9c30d5","execution":{"iopub.status.busy":"2023-05-14T08:03:03.546785Z","iopub.execute_input":"2023-05-14T08:03:03.547734Z","iopub.status.idle":"2023-05-14T08:03:03.768987Z","shell.execute_reply.started":"2023-05-14T08:03:03.547641Z","shell.execute_reply":"2023-05-14T08:03:03.767961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaled_amount = df['scaled_amount']\nscaled_time = df['scaled_time']\n\ndf.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\ndf.insert(0, 'scaled_amount', scaled_amount)\ndf.insert(1, 'scaled_time', scaled_time)\n\n# Amount and Time are Scaled!\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T08:03:03.771204Z","iopub.execute_input":"2023-05-14T08:03:03.771859Z","iopub.status.idle":"2023-05-14T08:03:03.866089Z","shell.execute_reply.started":"2023-05-14T08:03:03.771576Z","shell.execute_reply":"2023-05-14T08:03:03.864909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(18,4))\n\namount_val = df['scaled_amount'].values\ntime_val = df['scaled_time'].values\n\nsns.distplot(amount_val, ax=ax[0], color='r')\nax[0].set_title('Distribution of Transaction Amount', fontsize=14)\n\nsns.distplot(time_val, ax=ax[1], color='b')\nax[1].set_title('Distribution of Transaction Time', fontsize=14)\n\n\n\nplt.show()","metadata":{"_kg_hide-input":true,"_cell_guid":"cee315f2-325f-42b6-a640-736f10c272cc","_uuid":"cfa51792bf6f8a6b318ae1bffcff4e922b1d1917","execution":{"iopub.status.busy":"2023-05-14T08:03:50.371134Z","iopub.execute_input":"2023-05-14T08:03:50.371577Z","iopub.status.idle":"2023-05-14T08:03:52.851593Z","shell.execute_reply.started":"2023-05-14T08:03:50.371504Z","shell.execute_reply":"2023-05-14T08:03:52.850120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting the Data ","metadata":{"_cell_guid":"a59c8c8d-a4bc-4671-aa2f-9f959c142cde","_uuid":"5119c4ea9e0b9031dbc5937b56323da224985024"}},{"cell_type":"code","source":"X = df.drop('Class', axis=1)\ny = df['Class']","metadata":{"execution":{"iopub.status.busy":"2023-05-14T08:06:03.512770Z","iopub.execute_input":"2023-05-14T08:06:03.513118Z","iopub.status.idle":"2023-05-14T08:06:03.704256Z","shell.execute_reply.started":"2023-05-14T08:06:03.513075Z","shell.execute_reply":"2023-05-14T08:06:03.703163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Under-Sampling","metadata":{"_cell_guid":"956d34b9-e562-4b70-a2f8-fbe060273a83","_uuid":"cc554c4ffec656cb38d01c034f2cd338e1cb4565"}},{"cell_type":"code","source":"df = df.sample(frac=1) # shuffle\n\nfraud_df = df.loc[df['Class'] == 1]\nnon_fraud_df = df.loc[df['Class'] == 0][:492]\n\nnormal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n\nnew_df = normal_distributed_df.sample(frac=1, random_state=42)\n\nnew_df.head()","metadata":{"_kg_hide-input":true,"_cell_guid":"f0acfc44-eb2a-4356-ad03-d0c12807acd7","_uuid":"e3a2b89752681164f14c8273452fc66734d7f41b","execution":{"iopub.status.busy":"2023-05-14T08:21:30.400046Z","iopub.execute_input":"2023-05-14T08:21:30.400401Z","iopub.status.idle":"2023-05-14T08:21:30.673823Z","shell.execute_reply.started":"2023-05-14T08:21:30.400349Z","shell.execute_reply":"2023-05-14T08:21:30.672582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Distribution of the Classes in the subsample dataset')\nprint(new_df['Class'].value_counts()/len(new_df))\n\n\n\nsns.countplot('Class', data=new_df, palette=colors)\nplt.title('Equally Distributed Classes', fontsize=14)\nplt.show()","metadata":{"_kg_hide-input":true,"_cell_guid":"73454100-dc69-49fd-b1b2-f72e326bca5d","_uuid":"68b42e92df59f10fbd3ba700389796c4506af604","execution":{"iopub.status.busy":"2023-05-14T08:21:38.081797Z","iopub.execute_input":"2023-05-14T08:21:38.082331Z","iopub.status.idle":"2023-05-14T08:21:38.323360Z","shell.execute_reply.started":"2023-05-14T08:21:38.082242Z","shell.execute_reply":"2023-05-14T08:21:38.321904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make sure we use the subsample in our correlation\n\nf, (ax1, ax2) = plt.subplots(2, 1, figsize=(24,20))\n\n# Entire DataFrame\ncorr = df.corr()\nsns.heatmap(corr, cmap='coolwarm_r', ax=ax1)\nax1.set_title(\"Imbalanced Correlation Matrix\", fontsize=14)\n\n\nsub_sample_corr = new_df.corr()\nsns.heatmap(sub_sample_corr, cmap='coolwarm_r', annot_kws={'size':20}, ax=ax2)\nax2.set_title('SubSample Correlation Matrix', fontsize=14)\nplt.show()","metadata":{"_kg_hide-input":true,"_cell_guid":"9f353623-9435-4bb2-b854-b4a201ec7dd9","_uuid":"e2f417c5d7c633a1e3cdfaa78acd6bd77a38400e","execution":{"iopub.status.busy":"2023-05-14T08:23:47.213397Z","iopub.execute_input":"2023-05-14T08:23:47.214084Z","iopub.status.idle":"2023-05-14T08:23:50.255704Z","shell.execute_reply.started":"2023-05-14T08:23:47.214016Z","shell.execute_reply":"2023-05-14T08:23:50.254775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n### Explaining Correlation: \n<ul>\n<li><b>Negative Correlations: </b>V17, V14, V12 and V10 are negatively correlated.The lower these values are, the more likely the end result will be a fraud transaction.  </li>\n<li> <b> Positive Correlations: </b> V2, V4, V11, and V19 are positively correlated. The higher these values are, the more likely the end result will be a fraud transaction. </li>\n","metadata":{"_cell_guid":"0abc31ee-a78e-43af-822f-f06772d00c1c","_uuid":"88477bac6687f110e9d64ec22837c250d85d2a2b"}},{"cell_type":"code","source":"f, axes = plt.subplots(ncols=4, figsize=(20,4))\n\n# Negative Correlations with our Class (The lower our feature value the more likely it will be a fraud transaction)\nsns.boxplot(x=\"Class\", y=\"V17\", data=new_df, palette=colors, ax=axes[0])\naxes[0].set_title('V17 vs Class Negative Correlation')\n\nsns.boxplot(x=\"Class\", y=\"V14\", data=new_df, palette=colors, ax=axes[1])\naxes[1].set_title('V14 vs Class Negative Correlation')\n\n\nsns.boxplot(x=\"Class\", y=\"V12\", data=new_df, palette=colors, ax=axes[2])\naxes[2].set_title('V12 vs Class Negative Correlation')\n\n\nsns.boxplot(x=\"Class\", y=\"V10\", data=new_df, palette=colors, ax=axes[3])\naxes[3].set_title('V10 vs Class Negative Correlation')\n\nplt.show()","metadata":{"_kg_hide-input":true,"_cell_guid":"2f02c21f-daa3-4251-a8e9-acad09a5ce0f","_uuid":"318d0e7e0443f99139be21c00a7abc663be26385","execution":{"iopub.status.busy":"2023-05-14T08:01:37.305717Z","iopub.execute_input":"2023-05-14T08:01:37.306071Z","iopub.status.idle":"2023-05-14T08:01:38.126327Z","shell.execute_reply.started":"2023-05-14T08:01:37.306003Z","shell.execute_reply":"2023-05-14T08:01:38.124951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, axes = plt.subplots(ncols=4, figsize=(20,4))\n\n# Positive correlations (The higher the feature the probability increases that it will be a fraud transaction)\nsns.boxplot(x=\"Class\", y=\"V11\", data=new_df, palette=colors, ax=axes[0])\naxes[0].set_title('V11 vs Class Positive Correlation')\n\nsns.boxplot(x=\"Class\", y=\"V4\", data=new_df, palette=colors, ax=axes[1])\naxes[1].set_title('V4 vs Class Positive Correlation')\n\n\nsns.boxplot(x=\"Class\", y=\"V2\", data=new_df, palette=colors, ax=axes[2])\naxes[2].set_title('V2 vs Class Positive Correlation')\n\n\nsns.boxplot(x=\"Class\", y=\"V19\", data=new_df, palette=colors, ax=axes[3])\naxes[3].set_title('V19 vs Class Positive Correlation')\n\nplt.show()","metadata":{"_kg_hide-input":true,"_cell_guid":"b457b10e-c17c-4cb2-9719-6d4128377c9f","_uuid":"7bfc46c028f8602ee949de83629082633aa47b2c","execution":{"iopub.status.busy":"2023-05-14T08:01:38.129195Z","iopub.execute_input":"2023-05-14T08:01:38.130531Z","iopub.status.idle":"2023-05-14T08:01:38.831980Z","shell.execute_reply.started":"2023-05-14T08:01:38.129669Z","shell.execute_reply":"2023-05-14T08:01:38.831061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* After showing the coloumns collerated to the target using boxplots\n=> outliers were found in features 10, 12, 14\n","metadata":{"_cell_guid":"93e56c89-185e-40d2-9ccc-29b123feb5a6","_uuid":"a721282c0f44ec8030bbad6d0220091bde8cbec8"}},{"cell_type":"code","source":"import numpy as np\n\ndef remove_outliers(df, columns):\n    for col in columns:\n        col_fraud = df.loc[df['Class'] == 1, col]\n        col_q25, col_q75 = np.percentile(col_fraud, [25, 75])\n        col_iqr = col_q75 - col_q25\n\n        col_cut_off = col_iqr * 1.5\n        col_lower, col_upper = col_q25 - col_cut_off, col_q75 + col_cut_off\n\n        df = df.drop(df[(df[col] > col_upper) | (df[col] < col_lower)].index)\n\n    return df","metadata":{"_kg_hide-input":true,"_cell_guid":"2e19fe33-f85a-4ffd-8e4a-807d0e0fb992","_uuid":"21e43406e62a9561fba2f065ce15a8d87a1bf389","execution":{"iopub.status.busy":"2023-05-14T09:40:47.073536Z","iopub.execute_input":"2023-05-14T09:40:47.073881Z","iopub.status.idle":"2023-05-14T09:40:47.082898Z","shell.execute_reply.started":"2023-05-14T09:40:47.073840Z","shell.execute_reply":"2023-05-14T09:40:47.081797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df = remove_outliers(new_df, ['V10', 'V12', 'V14'])","metadata":{"execution":{"iopub.status.busy":"2023-05-14T09:40:48.422153Z","iopub.execute_input":"2023-05-14T09:40:48.422502Z","iopub.status.idle":"2023-05-14T09:40:48.440322Z","shell.execute_reply.started":"2023-05-14T09:40:48.422451Z","shell.execute_reply":"2023-05-14T09:40:48.439160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,(ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,6))\n\ncolors = ['#B3F9C5', '#f9c5b3']\n# Boxplots with outliers removed\n# Feature V14\nsns.boxplot(x=\"Class\", y=\"V14\", data=new_df,ax=ax1, palette=colors)\nax1.set_title(\"V14 Feature \\n Reduction of outliers\", fontsize=14)\n\n# Feature 12\nsns.boxplot(x=\"Class\", y=\"V12\", data=new_df, ax=ax2, palette=colors)\nax2.set_title(\"V12 Feature \\n Reduction of outliers\", fontsize=14)\n\n# Feature V10\nsns.boxplot(x=\"Class\", y=\"V10\", data=new_df, ax=ax3, palette=colors)\nax3.set_title(\"V10 Feature \\n Reduction of outliers\", fontsize=14)\n\n\nplt.show()","metadata":{"_kg_hide-input":true,"_cell_guid":"66e44398-7c91-4cce-9778-4512cb838973","_uuid":"ac80d9cfb07f1865094a8d460ae801750e93d694","execution":{"iopub.status.busy":"2023-05-14T09:41:01.432667Z","iopub.execute_input":"2023-05-14T09:41:01.433289Z","iopub.status.idle":"2023-05-14T09:41:02.269668Z","shell.execute_reply.started":"2023-05-14T09:41:01.433233Z","shell.execute_reply":"2023-05-14T09:41:02.268627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# New_df is from the random undersample data (fewer instances)\nX = new_df.drop('Class', axis=1)\ny = new_df['Class']","metadata":{"_kg_hide-input":true,"_cell_guid":"f83cde6b-90d0-4e9d-ac63-fb69780431b2","_uuid":"af3027e7df67b75c92c88d597003632e285c9bff","execution":{"iopub.status.busy":"2023-05-14T08:31:51.220039Z","iopub.execute_input":"2023-05-14T08:31:51.220384Z","iopub.status.idle":"2023-05-14T08:31:51.234147Z","shell.execute_reply.started":"2023-05-14T08:31:51.220341Z","shell.execute_reply":"2023-05-14T08:31:51.232939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2> Classifiers </h2>","metadata":{"_cell_guid":"cb2c480a-090a-4cfb-b12e-3b74c325826c","_uuid":"1b63bfd92008043cc1a336f924c835e73792f6d8"}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"_kg_hide-input":true,"_cell_guid":"288a65b7-8b86-44b1-973d-38dbcfe82bbb","_uuid":"fb0a479efaa7147d6702c2c24083f1118621863f","execution":{"iopub.status.busy":"2023-05-14T08:34:01.283705Z","iopub.execute_input":"2023-05-14T08:34:01.284115Z","iopub.status.idle":"2023-05-14T08:34:01.292521Z","shell.execute_reply.started":"2023-05-14T08:34:01.284036Z","shell.execute_reply":"2023-05-14T08:34:01.291593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_classifiers(X_train, y_train, X_test, y_test):\n    classifiers = {\n        \"LogisiticRegression\": LogisticRegression(),\n        \"KNearest\": KNeighborsClassifier(),\n        \"Support Vector Classifier\": SVC(probability=True),\n        \"DecisionTreeClassifier\": DecisionTreeClassifier()\n    }\n\n    best_estimators = {}\n    cross_val_scores = {}\n    roc_auc_scores = {}\n\n    # Define the hyperparameters for each classifier\n    log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n    knears_params = {\"n_neighbors\": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n    svc_params = {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']}\n    tree_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,4,1)), \"min_samples_leaf\": list(range(5,7,1))}\n\n    # Loop through the classifiers\n    for name, clf in classifiers.items():\n        # Define the hyperparameters for the current classifier\n        if name == \"LogisiticRegression\":\n            params = log_reg_params\n        elif name == \"KNearest\":\n            params = knears_params\n        elif name == \"Support Vector Classifier\":\n            params = svc_params\n        elif name == \"DecisionTreeClassifier\":\n            params = tree_params\n\n        # Perform grid search to find the best estimator\n        grid_clf = GridSearchCV(clf, params)\n        grid_clf.fit(X_train, y_train)\n        best_estimators[name] = grid_clf.best_estimator_\n\n        # Evaluate the classifier using cross-validation\n        scores = cross_val_score(best_estimators[name], X_train, y_train, cv=5)\n        cross_val_scores[name] = scores.mean()\n\n        # Calculate the ROC AUC score on the test data\n        y_pred_proba = cross_val_predict(best_estimators[name], X_test, y_test, cv=5, method='predict_proba')[:,1]\n        roc_auc = roc_auc_score(y_test, y_pred_proba)\n        roc_auc_scores[name] = roc_auc\n\n    # Generate classification reports for each classifier\n    reports = {}\n    for name, clf in best_estimators.items():\n        y_pred = clf.predict(X_test)\n        report = classification_report(y_test, y_pred, target_names=['nonFraud', 'Fraud'])\n        reports[name] = report\n\n    return best_estimators, reports, cross_val_scores, roc_auc_scores","metadata":{"execution":{"iopub.status.busy":"2023-05-14T09:36:41.005279Z","iopub.execute_input":"2023-05-14T09:36:41.005639Z","iopub.status.idle":"2023-05-14T09:36:41.026503Z","shell.execute_reply.started":"2023-05-14T09:36:41.005596Z","shell.execute_reply":"2023-05-14T09:36:41.025244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_estimators, reports, cross_val_scores, roc_auc_scores = evaluate_classifiers(X_train, y_train, X_test, y_test)\n\nprint(\"---------------------------------------------\\n\")\n# Print the classification reports\nfor name, report in reports.items():\n    print(f\"Classification Report for {name}:\")\n    print(report)\n\nprint(\"---------------------------------------------\\n\")\n\n# Print the cross-validation scores\nfor name, score in cross_val_scores.items():\n    print(f\"Cross-validation score for {name}: {round(score.mean() * 100, 2).astype(str) + '%'}\")\nprint(\"---------------------------------------------\\n\")\n    \nfor name, score in roc_auc_scores.items():\n    print(f\"ROC AUC score for {name}: {round(score.mean() * 100, 2).astype(str) + '%'}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-14T09:36:43.882093Z","iopub.execute_input":"2023-05-14T09:36:43.882444Z","iopub.status.idle":"2023-05-14T09:36:56.166690Z","shell.execute_reply.started":"2023-05-14T09:36:43.882379Z","shell.execute_reply":"2023-05-14T09:36:56.165776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* A high ROC AUC indicates that the classifier is good at distinguishing between the two classes, such as **Logestic Regression**.\n* while a high F1 score indicates a good balance between precision and recall, such as **Support Vector Machine**.","metadata":{}},{"cell_type":"code","source":"def plot_learning_curve(best_estimators, X, y, ylim=None, cv=None, n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n    f, axes = plt.subplots(2, 2, figsize=(20, 14), sharey=True)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    for i, (name, estimator) in enumerate(best_estimators.items()):\n        ax = axes[i // 2, i % 2]\n        train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n                                                                train_sizes=train_sizes)\n        train_scores_mean = np.mean(train_scores, axis=1)\n        train_scores_std = np.std(train_scores, axis=1)\n        test_scores_mean = np.mean(test_scores, axis=1)\n        test_scores_std = np.std(test_scores, axis=1)\n        ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                         train_scores_mean + train_scores_std, alpha=0.1,\n                         color=\"#ff9124\")\n        ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                         test_scores_mean + test_scores_std, alpha=0.1, color=\"#2492ff\")\n        ax.plot(train_sizes, train_scores_mean, 'o-', color=\"#ff9124\",\n                 label=\"Training score\")\n        ax.plot(train_sizes, test_scores_mean, 'o-', color=\"#2492ff\",\n                 label=\"Cross-validation score\")\n        ax.set_title(f\"{name} Learning Curve\", fontsize=14)\n        ax.set_xlabel('Training size (m)')\n        ax.set_ylabel('Score')\n        ax.grid(True)\n        ax.legend(loc=\"best\")\n    return plt","metadata":{"_kg_hide-input":true,"_cell_guid":"bb72803c-3ea3-40cd-8ac3-399540ab7f5a","_uuid":"a12fb2f7e104931bb78e1bd6cfc5a516c970708b","execution":{"iopub.status.busy":"2023-05-14T09:51:45.391265Z","iopub.execute_input":"2023-05-14T09:51:45.391655Z","iopub.status.idle":"2023-05-14T09:51:45.409474Z","shell.execute_reply.started":"2023-05-14T09:51:45.391603Z","shell.execute_reply":"2023-05-14T09:51:45.408237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_learning_curve(best_estimators, X_train, y_train, cv=cv, n_jobs=-1)","metadata":{"_kg_hide-input":true,"_cell_guid":"5b8302aa-0207-455f-8c1a-78ff3e9b5141","_uuid":"15b262baa0c61c288a5453031b4d7f80f5a7a5ab","execution":{"iopub.status.busy":"2023-05-14T09:51:46.463753Z","iopub.execute_input":"2023-05-14T09:51:46.464106Z","iopub.status.idle":"2023-05-14T09:52:21.167759Z","shell.execute_reply.started":"2023-05-14T09:51:46.464047Z","shell.execute_reply":"2023-05-14T09:52:21.166804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n## Summary: \n<ul>\n    <li> <b> Logistic Regression and Support Vector Machine</b> classifiers are more accurate than the other three classifiers in most cases. (We will further analyze Logistic Regression) </li>\n<li><b> GridSearchCV </b> is used to determine the paremeters that gives the best predictive score for the classifiers. </li>\n<li> Logistic Regression has the best Receiving Operating Characteristic score  (ROC), meaning that LogisticRegression pretty accurately separates <b> fraud </b> and <b> non-fraud </b> transactions.</li>\n</ul>\n\n## Learning Curves:\n<ul>\n<li>The <b>wider the  gap</b>  between the training score and the cross validation score, the more likely your model is <b>overfitting (high variance)</b>.</li>\n<li> If the score is low in both training and cross-validation sets</b> this is an indication that our model is <b>underfitting (high bias)</b></li>\n<li><b> Support Vector Machine Classifier</b>  shows the best score in both training and cross-validating sets.</li>\n<li><b> Logistic Regression Classifier</b>  shows the best F1 score which indicates a good balance between precision and recall.</li>\n\n</ul>","metadata":{}},{"cell_type":"markdown","source":"### SMOTE Technique (Over-Sampling):\n<b>SMOTE</b> stands for Synthetic Minority Over-sampling Technique.  Unlike Random UnderSampling, SMOTE creates new synthetic points in order to have an equal balance of the classes. This is another alternative for solving the \"class imbalance problems\". <br><br>\n\n\n### Cross Validation Overfitting Mistake:\n## Overfitting during Cross Validation:  \nIn our undersample analysis, there was a mistake. If you want to undersample or oversample your data you should not do it before cross validating. Why because you will be directly influencing the validation set before implementing cross-validation causing a \"data leakage\" problem.","metadata":{"_cell_guid":"e70e913a-173b-401b-96ee-93ddda7374c0","_uuid":"d901eb00581cc890075a93d292935304e5b63355"}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\ndef evaluate_classifiers(X_train, y_train, X_test, y_test):\n    classifiers = {\n        \"LogisiticRegression\": LogisticRegression(),\n        \"KNearest\": KNeighborsClassifier(),\n        \"Support Vector Classifier\": SVC(probability=True),\n        \"DecisionTreeClassifier\": DecisionTreeClassifier()\n    }\n\n    best_estimators = {}\n    cross_val_scores = {}\n    roc_auc_scores = {}\n\n    # Define the hyperparameters for each classifier\n    log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n    knears_params = {\"n_neighbors\": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n    svc_params = {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']}\n    tree_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,4,1)), \"min_samples_leaf\": list(range(5,7,1))}\n\n    # Loop through the classifiers\n    for name, clf in classifiers.items():\n        # Define the hyperparameters for the current classifier\n        if name == \"LogisiticRegression\":\n            params = log_reg_params\n        elif name == \"KNearest\":\n            params = knears_params\n        elif name == \"Support Vector Classifier\":\n            params = svc_params\n        elif name == \"DecisionTreeClassifier\":\n            params = tree_params\n\n        # Perform grid search to find the best estimator\n        rand_grid_clf = RandomizedSearchCV(clf, params, n_iter=4)\n        pipeline = imbalanced_make_pipeline(SMOTE(sampling_strategy='minority'), rand_grid_clf) # SMOTE happens during Cross Validation not before..\n        model = pipeline.fit(X_train, y_train)\n        best_estimators[name] =  rand_grid_clf.best_estimator_\n\n        # Evaluate the classifier using cross-validation\n        scores = cross_val_score(best_estimators[name], X_train, y_train, cv=5)\n        cross_val_scores[name] = scores.mean()\n\n        # Calculate the ROC AUC score on the test data\n        y_pred_proba = cross_val_predict(best_estimators[name], X_test, y_test, cv=5, method='predict_proba')[:,1]\n        roc_auc = roc_auc_score(y_test, y_pred_proba)\n        roc_auc_scores[name] = roc_auc\n\n    # Generate classification reports for each classifier\n    reports = {}\n    for name, clf in best_estimators.items():\n        y_pred = clf.predict(X_test)\n        report = classification_report(y_test, y_pred, target_names=['nonFraud', 'Fraud'])\n        reports[name] = report\n\n    return best_estimators, reports, cross_val_scores, roc_auc_scores","metadata":{"execution":{"iopub.status.busy":"2023-05-14T10:13:35.610339Z","iopub.execute_input":"2023-05-14T10:13:35.610770Z","iopub.status.idle":"2023-05-14T10:13:35.633227Z","shell.execute_reply.started":"2023-05-14T10:13:35.610703Z","shell.execute_reply":"2023-05-14T10:13:35.631961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_estimators, reports, cross_val_scores, roc_auc_scores = evaluate_classifiers(X_train, y_train, X_test, y_test)\n\nprint(\"---------------------------------------------\\n\")\n# Print the classification reports\nfor name, report in reports.items():\n    print(f\"Classification Report for {name}:\")\n    print(report)\n\nprint(\"---------------------------------------------\\n\")\n\n# Print the cross-validation scores\nfor name, score in cross_val_scores.items():\n    print(f\"Cross-validation score for {name}: {round(score.mean() * 100, 2).astype(str) + '%'}\")\nprint(\"---------------------------------------------\\n\")\n    \nfor name, score in roc_auc_scores.items():\n    print(f\"ROC AUC score for {name}: {round(score.mean() * 100, 2).astype(str) + '%'}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-14T10:13:53.306855Z","iopub.execute_input":"2023-05-14T10:13:53.307253Z","iopub.status.idle":"2023-05-14T10:13:59.826711Z","shell.execute_reply.started":"2023-05-14T10:13:53.307186Z","shell.execute_reply":"2023-05-14T10:13:59.822664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Conclusion: \nImplementing SMOTE on our imbalanced dataset increased the overall score in all our models. \n","metadata":{"_cell_guid":"ee0932c1-e9dc-4135-93af-1972d07d3d0f","_uuid":"1b03ca4b3e37985bea49686abd466fdd9a7d84d3"}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}